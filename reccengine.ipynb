{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/__init__.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev  \u001b[38;5;66;03m# pyright: ignore # noqa:F401\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hashtable \u001b[38;5;28;01mas\u001b[39;00m _hashtable, lib \u001b[38;5;28;01mas\u001b[39;00m _lib, tslib \u001b[38;5;28;01mas\u001b[39;00m _tslib\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/compat/__init__.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m F\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     is_numpy_dev,\n\u001b[1;32m     20\u001b[0m     np_version_under1p21,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     pa_version_under1p01,\n\u001b[1;32m     24\u001b[0m     pa_version_under2p0,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     pa_version_under9p0,\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/compat/numpy/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\" support numpy compatibility across versions \"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# numpy versioning\u001b[39;00m\n\u001b[1;32m      7\u001b[0m _np_version \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39m__version__\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/util/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# pyright: reportUnusedImport = false\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     Appender,\n\u001b[1;32m      4\u001b[0m     Substitution,\n\u001b[1;32m      5\u001b[0m     cache_readonly,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhashing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     hash_array,\n\u001b[1;32m     10\u001b[0m     hash_pandas_object,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/util/_decorators.py:14\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     Any,\n\u001b[1;32m      8\u001b[0m     Callable,\n\u001b[1;32m      9\u001b[0m     Mapping,\n\u001b[1;32m     10\u001b[0m     cast,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproperties\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cache_readonly\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     F,\n\u001b[1;32m     17\u001b[0m     T,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_exceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_stack_level\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/__init__.py:13\u001b[0m\n\u001b[1;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaTType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterval\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m ]\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     NaT,\n\u001b[1;32m     16\u001b[0m     NaTType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     iNaT,\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/interval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN, SpectralClustering\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"combined_data_with_sentiment.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values in 'cleaned_reviews'\n",
    "data = data.dropna(subset=['cleaned_reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content-based filtering relies on the features of the items themselves (e.g., course descriptions, reviews, ratings). \n",
    "# Since you have a good amount of textual data in the cleaned_reviews, sentiment_score, rating, and other numeric features, \n",
    "# content-based filtering might be a good place to start.\n",
    "\n",
    "# Vectorize cleaned_reviews using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data['cleaned_reviews'])\n",
    "\n",
    "# Compute cosine similarity between courses\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Function to get the most similar courses for a given course index\n",
    "def get_similar_courses(course_index, cosine_sim, top_n=5):\n",
    "    sim_scores = list(enumerate(cosine_sim[course_index]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:top_n + 1]  # Skip the first score (itself)\n",
    "    course_indices = [i[0] for i in sim_scores]\n",
    "    return data.iloc[course_indices]\n",
    "\n",
    "# Get top 5 similar courses for the first course\n",
    "similar_courses = get_similar_courses(0, cosine_sim)\n",
    "print(similar_courses[['name', 'institution', 'rating']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_rated_similar_courses(course_index, cosine_sim, top_n=5):\n",
    "    similar_courses = get_similar_courses(course_index, cosine_sim, top_n)\n",
    "    similar_courses['rating'] = similar_courses['rating'].astype(float)\n",
    "    return similar_courses.sort_values(by='rating', ascending=False)\n",
    "\n",
    "top_rated_similar_courses = get_top_rated_similar_courses(0, cosine_sim)\n",
    "print(top_rated_similar_courses[['name', 'rating']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing text data (cleaned_reviews)\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data['cleaned_reviews'])\n",
    "\n",
    "# Preprocessing numeric features (rating, review_count, sentiment_score, avg_rating)\n",
    "numeric_features = data[['rating', 'review_count', 'sentiment_score', 'avg_rating']]\n",
    "scaler = StandardScaler()\n",
    "numeric_features_scaled = scaler.fit_transform(numeric_features)\n",
    "\n",
    "# Combine TF-IDF and numeric features into a single feature matrix\n",
    "combined_features = hstack([tfidf_matrix, numeric_features_scaled])\n",
    "\n",
    "# Clustering with KMeans\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(combined_features)\n",
    "data['kmeans_cluster'] = kmeans.labels_\n",
    "\n",
    "# Clustering with DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "dbscan_labels = dbscan.fit_predict(combined_features)\n",
    "data['dbscan_cluster'] = dbscan_labels\n",
    "\n",
    "# Clustering with Spectral Clustering\n",
    "similarity_matrix = cosine_similarity(combined_features)\n",
    "spectral_clustering = SpectralClustering(n_clusters=5, affinity='precomputed')\n",
    "spectral_labels = spectral_clustering.fit_predict(similarity_matrix)\n",
    "data['spectral_cluster'] = spectral_labels\n",
    "\n",
    "# Function to recommend courses based on clustering\n",
    "def recommend_courses(course_index, cluster_column='kmeans_cluster', num_recommendations=5):\n",
    "    cluster_id = data.iloc[course_index][cluster_column]\n",
    "    similar_courses = data[data[cluster_column] == cluster_id]\n",
    "    return similar_courses[['name', 'institution', 'rating']].head(num_recommendations)\n",
    "\n",
    "# Example: Recommend 5 courses similar to course at index 0 based on KMeans cluster\n",
    "recommended_courses_kmeans = recommend_courses(0, cluster_column='kmeans_cluster')\n",
    "print(\"KMeans Recommendations:\")\n",
    "print(recommended_courses_kmeans)\n",
    "\n",
    "# Visualize the clusters for KMeans (using rating and review_count for simplicity)\n",
    "plt.scatter(data['rating'], data['review_count'], c=data['kmeans_cluster'], cmap='viridis')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Review Count')\n",
    "plt.title('KMeans Clustering')\n",
    "plt.show()\n",
    "\n",
    "# Visualize the clusters for DBSCAN\n",
    "plt.scatter(data['rating'], data['review_count'], c=data['dbscan_cluster'], cmap='viridis')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Review Count')\n",
    "plt.title('DBSCAN Clustering')\n",
    "plt.show()\n",
    "\n",
    "# Visualize the clusters for Spectral Clustering\n",
    "plt.scatter(data['rating'], data['review_count'], c=data['spectral_cluster'], cmap='viridis')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Review Count')\n",
    "plt.title('Spectral Clustering')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate clustering performance using silhouette score\n",
    "silhouette_kmeans = silhouette_score(combined_features, kmeans.labels_)\n",
    "silhouette_dbscan = silhouette_score(combined_features, dbscan_labels) if len(set(dbscan_labels)) > 1 else -1\n",
    "silhouette_spectral = silhouette_score(combined_features, spectral_labels)\n",
    "\n",
    "print(f\"Silhouette Score for KMeans: {silhouette_kmeans}\")\n",
    "print(f\"Silhouette Score for DBSCAN: {silhouette_dbscan}\")\n",
    "print(f\"Silhouette Score for Spectral Clustering: {silhouette_spectral}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing text data (cleaned_reviews)\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data['cleaned_reviews'])\n",
    "\n",
    "# Preprocessing numeric features (rating, review_count, sentiment_score, avg_rating)\n",
    "numeric_features = data[['rating', 'review_count', 'sentiment_score', 'avg_rating']]\n",
    "scaler = StandardScaler()\n",
    "numeric_features_scaled = scaler.fit_transform(numeric_features)\n",
    "\n",
    "# Combine TF-IDF and numeric features into a single feature matrix\n",
    "combined_features = hstack([tfidf_matrix, numeric_features_scaled])\n",
    "\n",
    "# Clustering with KMeans\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(combined_features)\n",
    "data['kmeans_cluster'] = kmeans.labels_\n",
    "\n",
    "# Clustering with DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "dbscan_labels = dbscan.fit_predict(combined_features)\n",
    "data['dbscan_cluster'] = dbscan_labels\n",
    "\n",
    "# Clustering with Spectral Clustering\n",
    "similarity_matrix = cosine_similarity(combined_features)\n",
    "spectral_clustering = SpectralClustering(n_clusters=5, affinity='precomputed')\n",
    "spectral_labels = spectral_clustering.fit_predict(similarity_matrix)\n",
    "data['spectral_cluster'] = spectral_labels\n",
    "\n",
    "# Content-Based Filtering\n",
    "def content_based_recommendations(course_index, top_n=5):\n",
    "    # Get the TF-IDF vector for the given course\n",
    "    course_vector = tfidf_matrix[course_index]\n",
    "    \n",
    "    # Calculate cosine similarities with all other courses\n",
    "    cosine_similarities = cosine_similarity(course_vector, tfidf_matrix)\n",
    "    \n",
    "    # Flatten the array and sort by similarity\n",
    "    similarity_scores = cosine_similarities.flatten()\n",
    "    similar_indices = similarity_scores.argsort()[-top_n-1:-1][::-1]  # Top N courses excluding the course itself\n",
    "    \n",
    "    # Return the recommended courses\n",
    "    return data.iloc[similar_indices][['name', 'institution', 'rating']]\n",
    "\n",
    "# Example: Recommend 5 courses similar to the course at index 0 based on content (TF-IDF similarity)\n",
    "recommended_courses_content = content_based_recommendations(0)\n",
    "print(\"Content-Based Recommendations:\")\n",
    "print(recommended_courses_content)\n",
    "\n",
    "# Function to recommend courses based on clustering\n",
    "def recommend_courses(course_index, cluster_column='kmeans_cluster', num_recommendations=5):\n",
    "    cluster_id = data.iloc[course_index][cluster_column]\n",
    "    similar_courses = data[data[cluster_column] == cluster_id]\n",
    "    return similar_courses[['name', 'institution', 'rating']].head(num_recommendations)\n",
    "\n",
    "# Example: Recommend 5 courses similar to course at index 0 based on KMeans cluster\n",
    "recommended_courses_kmeans = recommend_courses(0, cluster_column='kmeans_cluster')\n",
    "print(\"KMeans Recommendations:\")\n",
    "print(recommended_courses_kmeans)\n",
    "\n",
    "# Visualize the clusters for KMeans (using rating and review_count for simplicity)\n",
    "plt.scatter(data['rating'], data['review_count'], c=data['kmeans_cluster'], cmap='viridis')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Review Count')\n",
    "plt.title('KMeans Clustering')\n",
    "plt.show()\n",
    "\n",
    "# Visualize the clusters for DBSCAN\n",
    "plt.scatter(data['rating'], data['review_count'], c=data['dbscan_cluster'], cmap='viridis')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Review Count')\n",
    "plt.title('DBSCAN Clustering')\n",
    "plt.show()\n",
    "\n",
    "# Visualize the clusters for Spectral Clustering\n",
    "plt.scatter(data['rating'], data['review_count'], c=data['spectral_cluster'], cmap='viridis')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Review Count')\n",
    "plt.title('Spectral Clustering')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate clustering performance using silhouette score\n",
    "silhouette_kmeans = silhouette_score(combined_features, kmeans.labels_)\n",
    "silhouette_dbscan = silhouette_score(combined_features, dbscan_labels) if len(set(dbscan_labels)) > 1 else -1\n",
    "silhouette_spectral = silhouette_score(combined_features, spectral_labels)\n",
    "\n",
    "print(f\"Silhouette Score for KMeans: {silhouette_kmeans}\")\n",
    "print(f\"Silhouette Score for DBSCAN: {silhouette_dbscan}\")\n",
    "print(f\"Silhouette Score for Spectral Clustering: {silhouette_spectral}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
