{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/combined_data_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering: Calculate Average Rating, Review Count per Course\n",
    "course_stats = df.groupby('course_id').agg(\n",
    "    avg_rating=('rating', 'mean'),\n",
    "    review_count=('rating', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Merge back into original dataframe\n",
    "df = df.merge(course_stats, on='course_id', how='left')\n",
    "\n",
    "# 5. Normalize Rating and Review Count\n",
    "scaler = StandardScaler()\n",
    "df[['normalized_rating', 'normalized_review_count']] = scaler.fit_transform(\n",
    "    df[['avg_rating', 'review_count']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = df\n",
    "\n",
    "# Replace NaN values in the 'cleaned_reviews' column with an empty string\n",
    "combined_data['cleaned_reviews'] = combined_data['cleaned_reviews'].fillna('')\n",
    "# Initialize TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))  # Adjust max_features based on your data size\n",
    "X = vectorizer.fit_transform(combined_data['cleaned_reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(combined_data['cleaned_reviews'])\n",
    "X = tokenizer.texts_to_sequences(combined_data['cleaned_reviews'])\n",
    "X = pad_sequences(X, maxlen=200)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, combined_data['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Building the LSTM model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=128, input_length=200),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = tokenizer.texts_to_sequences(combined_data['cleaned_reviews'])\n",
    "X_new = pad_sequences(X_new, maxlen=200)\n",
    "combined_data['predicted_sentiment'] = (model.predict(X_new) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pre-trained Sentiment Models (Unsupervised Approach)\n",
    "\n",
    "data = df\n",
    "\n",
    "# Initialize VADER Sentiment Analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Apply sentiment analysis to your reviews\n",
    "data['sentiment_score'] = data['cleaned_reviews'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "\n",
    "# Classify sentiment as positive (1), neutral (0), or negative (-1)\n",
    "data['predicted_sentiment'] = data['sentiment_score'].apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>institution</th>\n",
       "      <th>course_url</th>\n",
       "      <th>course_id</th>\n",
       "      <th>reviews</th>\n",
       "      <th>reviewers</th>\n",
       "      <th>date_reviews</th>\n",
       "      <th>rating</th>\n",
       "      <th>cleaned_reviews</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>review_count</th>\n",
       "      <th>normalized_rating</th>\n",
       "      <th>normalized_review_count</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>https://www.coursera.org/learn/machine-learning</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>This is an extremely basic course. Machine lea...</td>\n",
       "      <td>By Deleted A</td>\n",
       "      <td>2017-03-18</td>\n",
       "      <td>1</td>\n",
       "      <td>extremely basic course machine learning built ...</td>\n",
       "      <td>4.750522</td>\n",
       "      <td>35895</td>\n",
       "      <td>0.277835</td>\n",
       "      <td>2.014232</td>\n",
       "      <td>-0.0262</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>https://www.coursera.org/learn/machine-learning</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>The course is ok but the certification procedu...</td>\n",
       "      <td>By Bruno C</td>\n",
       "      <td>2015-11-09</td>\n",
       "      <td>1</td>\n",
       "      <td>course ok certification procedure messno state...</td>\n",
       "      <td>4.750522</td>\n",
       "      <td>35895</td>\n",
       "      <td>0.277835</td>\n",
       "      <td>2.014232</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>https://www.coursera.org/learn/machine-learning</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>I just started week 3 , I have to admit that I...</td>\n",
       "      <td>By Fadi</td>\n",
       "      <td>2019-04-15</td>\n",
       "      <td>1</td>\n",
       "      <td>started week admit good course explaining idea...</td>\n",
       "      <td>4.750522</td>\n",
       "      <td>35895</td>\n",
       "      <td>0.277835</td>\n",
       "      <td>2.014232</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>https://www.coursera.org/learn/machine-learning</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>This course is absolute garbage.  You get no f...</td>\n",
       "      <td>By Mathew L</td>\n",
       "      <td>2015-09-25</td>\n",
       "      <td>1</td>\n",
       "      <td>course absolute garbage get feedback quiz assi...</td>\n",
       "      <td>4.750522</td>\n",
       "      <td>35895</td>\n",
       "      <td>0.277835</td>\n",
       "      <td>2.014232</td>\n",
       "      <td>-0.4936</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>https://www.coursera.org/learn/machine-learning</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>However good the material and lectures may be,...</td>\n",
       "      <td>By Rui C</td>\n",
       "      <td>2015-12-12</td>\n",
       "      <td>1</td>\n",
       "      <td>however good material lecture may use outdated...</td>\n",
       "      <td>4.750522</td>\n",
       "      <td>35895</td>\n",
       "      <td>0.277835</td>\n",
       "      <td>2.014232</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name          institution  \\\n",
       "0  Machine Learning  Stanford University   \n",
       "1  Machine Learning  Stanford University   \n",
       "2  Machine Learning  Stanford University   \n",
       "3  Machine Learning  Stanford University   \n",
       "4  Machine Learning  Stanford University   \n",
       "\n",
       "                                        course_url         course_id  \\\n",
       "0  https://www.coursera.org/learn/machine-learning  machine-learning   \n",
       "1  https://www.coursera.org/learn/machine-learning  machine-learning   \n",
       "2  https://www.coursera.org/learn/machine-learning  machine-learning   \n",
       "3  https://www.coursera.org/learn/machine-learning  machine-learning   \n",
       "4  https://www.coursera.org/learn/machine-learning  machine-learning   \n",
       "\n",
       "                                             reviews     reviewers  \\\n",
       "0  This is an extremely basic course. Machine lea...  By Deleted A   \n",
       "1  The course is ok but the certification procedu...    By Bruno C   \n",
       "2  I just started week 3 , I have to admit that I...       By Fadi   \n",
       "3  This course is absolute garbage.  You get no f...   By Mathew L   \n",
       "4  However good the material and lectures may be,...      By Rui C   \n",
       "\n",
       "  date_reviews  rating                                    cleaned_reviews  \\\n",
       "0   2017-03-18       1  extremely basic course machine learning built ...   \n",
       "1   2015-11-09       1  course ok certification procedure messno state...   \n",
       "2   2019-04-15       1  started week admit good course explaining idea...   \n",
       "3   2015-09-25       1  course absolute garbage get feedback quiz assi...   \n",
       "4   2015-12-12       1  however good material lecture may use outdated...   \n",
       "\n",
       "   avg_rating  review_count  normalized_rating  normalized_review_count  \\\n",
       "0    4.750522         35895           0.277835                 2.014232   \n",
       "1    4.750522         35895           0.277835                 2.014232   \n",
       "2    4.750522         35895           0.277835                 2.014232   \n",
       "3    4.750522         35895           0.277835                 2.014232   \n",
       "4    4.750522         35895           0.277835                 2.014232   \n",
       "\n",
       "   sentiment_score  predicted_sentiment  \n",
       "0          -0.0262                   -1  \n",
       "1           0.3612                    1  \n",
       "2           0.8360                    1  \n",
       "3          -0.4936                   -1  \n",
       "4           0.5859                    1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulgupta/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0 reviews:\n",
      "317                   good so far\n",
      "330                   good so far\n",
      "343                   good so far\n",
      "900    It's very good for a start\n",
      "903       Good course though.... \n",
      "Name: reviews, dtype: object\n",
      "\n",
      "Cluster 1 reviews:\n",
      "0    This is an extremely basic course. Machine lea...\n",
      "1    The course is ok but the certification procedu...\n",
      "2    I just started week 3 , I have to admit that I...\n",
      "3    This course is absolute garbage.  You get no f...\n",
      "4    However good the material and lectures may be,...\n",
      "Name: reviews, dtype: object\n",
      "\n",
      "Cluster 2 reviews:\n",
      "77     Python should have been great language for thi...\n",
      "102    Python should have been great language for thi...\n",
      "127    Python should have been great language for thi...\n",
      "971                                                Great\n",
      "979                                                Great\n",
      "Name: reviews, dtype: object\n",
      "                                             reviews predicted_sentiment\n",
      "0  This is an extremely basic course. Machine lea...             neutral\n",
      "1  The course is ok but the certification procedu...             neutral\n",
      "2  I just started week 3 , I have to admit that I...             neutral\n",
      "3  This course is absolute garbage.  You get no f...             neutral\n",
      "4  However good the material and lectures may be,...             neutral\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "combined_data = pd.read_csv('Data/combined_data_preprocessed.csv')\n",
    "\n",
    "# 1. Vectorize the reviews using TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X = vectorizer.fit_transform(combined_data['reviews'])\n",
    "\n",
    "# 2. Apply KMeans clustering\n",
    "n_clusters = 3  # We'll start with 3 clusters (positive, neutral, negative)\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "combined_data['cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "# 3. Inspect the reviews in each cluster to assign sentiment labels\n",
    "# You can manually look at some of the reviews in each cluster and assign labels\n",
    "# Let's view a sample of reviews for each cluster\n",
    "\n",
    "for cluster in range(n_clusters):\n",
    "    print(f\"\\nCluster {cluster} reviews:\")\n",
    "    print(combined_data[combined_data['cluster'] == cluster]['reviews'].head(5))  # Show top 5 reviews in the cluster\n",
    "\n",
    "# 4. Manually label the clusters as 'positive', 'negative', or 'neutral'\n",
    "# After inspecting, you can assign a sentiment label to each cluster.\n",
    "# For example:\n",
    "cluster_sentiment_mapping = {\n",
    "    0: 'negative',  # Assign label based on your manual inspection\n",
    "    1: 'neutral',\n",
    "    2: 'positive'\n",
    "}\n",
    "\n",
    "# Assign sentiment labels to each review based on its cluster\n",
    "combined_data['predicted_sentiment'] = combined_data['cluster'].map(cluster_sentiment_mapping)\n",
    "\n",
    "# Now let's inspect the final results\n",
    "print(combined_data[['reviews', 'predicted_sentiment']].head())\n",
    "\n",
    "# Optionally, save the resulting data to a new CSV file\n",
    "combined_data.to_csv('sentiment_analysis_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 2. Apply Spectral Clustering\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# n_clusters specifies the number of clusters we want to form\u001b[39;00m\n\u001b[1;32m      9\u001b[0m spectral \u001b[38;5;241m=\u001b[39m SpectralClustering(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, affinity\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m combined_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mspectral\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 3. Inspect the reviews in each cluster to assign sentiment labels\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cluster \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39munique(combined_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_spectral.py:785\u001b[0m, in \u001b[0;36mSpectralClustering.fit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    764\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform spectral clustering on `X` and return cluster labels.\u001b[39;00m\n\u001b[1;32m    765\u001b[0m \n\u001b[1;32m    766\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[38;5;124;03m        Cluster labels.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 785\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/base.py:734\u001b[0m, in \u001b[0;36mClusterMixin.fit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;124;03mPerform clustering on `X` and returns cluster labels.\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;124;03m    Cluster labels.\u001b[39;00m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_spectral.py:745\u001b[0m, in \u001b[0;36mSpectralClustering.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    743\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdegree\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree\n\u001b[1;32m    744\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoef0\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef0\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maffinity_matrix_ \u001b[38;5;241m=\u001b[39m \u001b[43mpairwise_kernels\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maffinity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    749\u001b[0m random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_ \u001b[38;5;241m=\u001b[39m spectral_clustering(\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maffinity_matrix_,\n\u001b[1;32m    752\u001b[0m     n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    759\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    760\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:2205\u001b[0m, in \u001b[0;36mpairwise_kernels\u001b[0;34m(X, Y, metric, filter_params, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   2202\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown kernel \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m metric)\n\u001b[0;32m-> 2205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parallel_pairwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1579\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1576\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[1;32m   1578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1581\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[1;32m   1582\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1401\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1399\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m normalize(Y, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 1401\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_normalized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdense_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/extmath.py:189\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    187\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    192\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    196\u001b[0m ):\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/scipy/sparse/_base.py:630\u001b[0m, in \u001b[0;36mspmatrix.__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScalar operands are not allowed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    629\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mul_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/scipy/sparse/_base.py:541\u001b[0m, in \u001b[0;36mspmatrix._mul_dispatch\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m other\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    540\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimension mismatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mul_sparse_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;66;03m# If it's a list or whatever, treat it like a matrix\u001b[39;00m\n\u001b[1;32m    544\u001b[0m other_a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(other)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/scipy/sparse/_compressed.py:518\u001b[0m, in \u001b[0;36m_cs_matrix._mul_sparse_matrix\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    514\u001b[0m idx_dtype \u001b[38;5;241m=\u001b[39m get_index_dtype((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices,\n\u001b[1;32m    515\u001b[0m                              other\u001b[38;5;241m.\u001b[39mindptr, other\u001b[38;5;241m.\u001b[39mindices))\n\u001b[1;32m    517\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_sparsetools, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_matmat_maxnnz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 518\u001b[0m nnz \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m         \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m         \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m         \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m         \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    524\u001b[0m idx_dtype \u001b[38;5;241m=\u001b[39m get_index_dtype((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices,\n\u001b[1;32m    525\u001b[0m                              other\u001b[38;5;241m.\u001b[39mindptr, other\u001b[38;5;241m.\u001b[39mindices),\n\u001b[1;32m    526\u001b[0m                             maxval\u001b[38;5;241m=\u001b[39mnnz)\n\u001b[1;32m    528\u001b[0m indptr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(major_axis \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "# 1. Vectorize the reviews using TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X = vectorizer.fit_transform(combined_data['reviews'])\n",
    "\n",
    "# 2. Apply Spectral Clustering\n",
    "# n_clusters specifies the number of clusters we want to form\n",
    "spectral = SpectralClustering(n_clusters=3, affinity='cosine', random_state=42)\n",
    "combined_data['cluster'] = spectral.fit_predict(X)\n",
    "\n",
    "# 3. Inspect the reviews in each cluster to assign sentiment labels\n",
    "for cluster in np.unique(combined_data['cluster']):\n",
    "    print(f\"\\nCluster {cluster} reviews:\")\n",
    "    print(combined_data[combined_data['cluster'] == cluster]['reviews'].head(5))  # Show top 5 reviews in the cluster\n",
    "\n",
    "# 4. Manually label the clusters based on their content\n",
    "# Assign sentiment labels like this after inspecting the clusters\n",
    "cluster_sentiment_mapping = {\n",
    "    0: 'negative',  # Assign label based on inspection\n",
    "    1: 'positive',\n",
    "    2: 'neutral'\n",
    "}\n",
    "\n",
    "# Assign sentiment labels based on the cluster\n",
    "combined_data['predicted_sentiment'] = combined_data['cluster'].map(cluster_sentiment_mapping)\n",
    "\n",
    "# Inspect the final results\n",
    "print(combined_data[['reviews', 'predicted_sentiment']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
